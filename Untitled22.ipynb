{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMVeqepoAezVSmBnBYIos5k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VITIN187/VITIN187/blob/main/Untitled22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKcu5sXZmV1F",
        "outputId": "539813bb-3425-4c77-dce9-a5d14cb73148"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 696 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.4 [186 kB]\n",
            "Fetched 186 kB in 1s (205 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 121918 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.4) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.4) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ],
      "source": [
        "!apt install poppler-utils\n",
        "import google.generativeai as genai\n",
        "import PIL.Image\n",
        "import pathlib\n",
        "import tqdm\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "genai.configure(api_key=\"AIzaSyDP4RQ0znC6eNJwIjgoWoCkCjUShvmikpI\")\n"
      ],
      "metadata": {
        "id": "X7DxK0PBnOWZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models():\n",
        "    if 'generateContent' in m.supported_generation_methods:\n",
        "        print(m.name)\n",
        "model = genai.GenerativeModel('gemini-pro')\n",
        "response = model.generate_content(\"Qual o sentido da vida?\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "UDqpwNeFndpf",
        "outputId": "c2dde1f8-1ec3-46b7-f73f-169ec9010246"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-1.5-flash\n",
            "models/gemini-1.5-flash-001\n",
            "models/gemini-1.5-flash-latest\n",
            "models/gemini-1.5-pro\n",
            "models/gemini-1.5-pro-001\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n",
            "O sentido da vida é uma questão filosófica e pessoal que tem sido ponderada por pessoas ao longo da história. Não existe uma resposta definitiva que seja universalmente aceita, mas aqui estão algumas perspectivas comuns:\n",
            "\n",
            "**Perspectivas sobre o Sentido da Vida:**\n",
            "\n",
            "* **Propósito Pessoal:** Encontrar um objetivo ou missão que traga significado e satisfação à sua vida. Isso pode envolver uma carreira, um hobby, um relacionamento significativo ou um serviço aos outros.\n",
            "* **Valores e Crenças:** Viver de acordo com seus valores e crenças éticas, morais e espirituais. Isso pode criar uma sensação de propósito e orientação.\n",
            "* **Conexões:** Construir e manter relacionamentos significativos com familiares, amigos e outras pessoas importantes traz um senso de pertencimento e significado.\n",
            "* **Experiências:** Explorar o mundo, aprender coisas novas e vivenciar momentos de beleza e alegria podem enriquecer a vida e dar-lhe um senso de propósito.\n",
            "* **Contribuições:** Deixar um legado ou fazer uma diferença positiva no mundo pode criar um senso de significado e impacto.\n",
            "* **Evolução Pessoal:** Crescimento, aprendizagem e autoaperfeiçoamento contínuos podem trazer um senso de propósito e realização.\n",
            "* **Espiritualidade:** Conectar-se a um poder superior ou a um sistema de crenças espirituais pode fornecer conforto, orientação e um senso de significado.\n",
            "* **Busca Contínua:** O próprio processo de busca pelo significado da vida pode ser gratificante em si, mesmo que nunca se chegue a uma resposta definitiva.\n",
            "\n",
            "**Conclusão:**\n",
            "\n",
            "O sentido da vida é uma jornada pessoal e subjetiva. Não existe uma resposta única que sirva para todos. Ao explorar diferentes perspectivas e refletir sobre seus próprios valores, você pode descobrir o que dá significado e propósito à sua própria vida.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models():\n",
        "    if 'generateContent' in m.supported_generation_methods:\n",
        "        print(m.name)\n",
        "model = genai.GenerativeModel('gemini-pro')\n",
        "chat = model.start_chat(history=[])\n",
        "bem_vindo = \"# Bem Vindo ao Assistente Gemini IA UNIFATEC-PR #\"\n",
        "print(len(bem_vindo) * \"#\")\n",
        "print(bem_vindo)\n",
        "print(len(bem_vindo) * \"#\")\n",
        "print(\"### Digite 'sair' para encerrar ###\")\n",
        "print(\"\")\n",
        "while True:\n",
        "    texto = input(\"Escreva sua mensagem: \")\n",
        "    if texto == \"sair\":\n",
        "        break\n",
        "    response = chat.send_message(texto)\n",
        "    print(\"Gemini:\", response.text, \"\\n\")\n",
        "print(\"Encerrando Chat\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 664
        },
        "id": "7Ut8-nQfn99m",
        "outputId": "5dda56fd-bc73-4292-c2cb-a41399fcba5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-1.5-flash\n",
            "models/gemini-1.5-flash-001\n",
            "models/gemini-1.5-flash-latest\n",
            "models/gemini-1.5-pro\n",
            "models/gemini-1.5-pro-001\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n",
            "#################################################\n",
            "# Bem Vindo ao Assistente Gemini IA UNIFATEC-PR #\n",
            "#################################################\n",
            "### Digite 'sair' para encerrar ###\n",
            "\n",
            "Escreva sua mensagem: SAIR\n",
            "Gemini: Até a próxima! \n",
            "\n",
            "Escreva sua mensagem: SAIR\n",
            "Gemini: Adeus! Espero vê-lo novamente em breve. \n",
            "\n",
            "Escreva sua mensagem: OLÁ TUDO BEM\n",
            "Gemini: Olá! Tudo bem, obrigado por perguntar. E você? \n",
            "\n",
            "Escreva sua mensagem: SIM ESTOU\n",
            "Gemini: Fico feliz em ouvir isso! O que você gostaria de fazer hoje? \n",
            "\n",
            "Escreva sua mensagem: SAIR\n",
            "Gemini: Claro, até a próxima! \n",
            "\n",
            "Escreva sua mensagem: TCHAU\n",
            "Gemini: Tchau, tchau! \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL.Image\n",
        "for m in genai.list_models():\n",
        "if 'generateContent' in m.supported_generation_methods:\n",
        "print(m.name)\n",
        "model = genai.GenerativeModel('gemini-pro-vision')\n",
        "img = PIL.Image.open('DSC_1165.JPG')\n",
        "response = model.generate_content(img)\n",
        "print(\"Resposta 1:\", response.text)\n",
        "response = model.generate_content([\"Descreva a imagem e depois diga quantos animais tem nessa imagem?\", img])\n",
        "response.resolve()\n",
        "print(\"Resposta da pergunta\", response.text)"
      ],
      "metadata": {
        "id": "Upv1RQ-ooB5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "URL =\n",
        "\"https://storage.googleapis.com/generativeai-downloads/data/State_of_the_Uni\n",
        "on_Address_30_January_1961.mp3\"\n",
        "!wget -q $URL -O sample.mp3\n",
        "your_file = genai.upload_file(path='sample.mp3')"
      ],
      "metadata": {
        "id": "WXTS4RwMojyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Faça um resumo do conteúdo do audio\"\n",
        "model = genai.GenerativeModel('models/gemini-1.5-pro-latest')\n",
        "response = model.generate_content([prompt, your_file])\n",
        "print(response.text)\n"
      ],
      "metadata": {
        "id": "AaUtLCVno_tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not pathlib.Path('test.pdf').exists():\n",
        "!curl -o test.pdf\n",
        "https://asset\n",
        "s.openstax.org/oscms-prodcms/media/documents/UniversityPhysicsVolume2-\n",
        "WEB_5eNhMSa.pdf"
      ],
      "metadata": {
        "id": "nCVnca3vpCIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first = 121\n",
        "last = 154"
      ],
      "metadata": {
        "id": "Gik8HmG3pFCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir output\n",
        "!pdftoppm test.pdf -f {first} -l {last} output/images -jpeg\n",
        "!ls output\n",
        "12) Podemos abrir as imagens dentro do Colab\n",
        "img = PIL.Image.open(f\"output/images-{first}.jpg\")\n",
        "img.thumbnail([600, 600])\n",
        "img\n"
      ],
      "metadata": {
        "id": "k0DJTU5_pHJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for page_number in range(first,last+1):\n",
        "page_number = f\"{page_number:03d}\"\n",
        "! pdftotext test.pdf -f {page_number} -l {page_number}\n",
        "! mv test.txt output/text-{page_number}.txt\n",
        "!ls output"
      ],
      "metadata": {
        "id": "eqIBerzUpKrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = []\n",
        "image_files = list(pathlib.Path(\"output\").glob('images-*.jpg'))\n",
        "for img in tqdm.tqdm(image_files):\n",
        "files.append(genai.upload_file(img))\n",
        "texts = [t.read_text() for t in pathlib.Path(\"output\").glob('text-*.txt')]\n",
        "textbook = []\n",
        "for page, (text, image) in enumerate(zip(texts, files)):\n",
        "textbook.append(f'## Page {first+page} ##')\n",
        "textbook.append(text)\n",
        "textbook.append(image)\n"
      ],
      "metadata": {
        "id": "UrtDWAYBpLYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(model_name='gemini-1.5-pro-latest')\n",
        "response = model.generate_content(\n",
        "['# Aqui está o capítulo de um livro:']+\n",
        "textbook +\n",
        "[\"[END]\\n\\nFaça seu resumo\"]\n",
        ")\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "AkJE9bOppPpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from random import randint\n",
        "from typing import Iterable\n",
        "import google.generativeai as genai\n",
        "from google.api_core import retry"
      ],
      "metadata": {
        "id": "AYs8TyWEphB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "order = [] # o pedido em andamento.\n",
        "placed_order = [] # quando confirmar, envia o pedido para cozinha.\n",
        "def add_to_order(drink: str, modifiers: Iterable[str] = ()) -> None:\n",
        "\"\"\"Adiciona a bebida especificada ao pedido do cliente, incluindo\n",
        "quaisquer modificadores.\"\"\"\n",
        "order.append((drink, modifiers))\n",
        "def get_order() -> Iterable[tuple[str, Iterable[str]]]:\n",
        "\"\"\"Retorna o pedido do cliente.\"\"\"\n",
        "return order\n",
        "def remove_item(n: int) -> str:\n",
        "\"\"\"Remova o n item (baseado em um) do pedido.\n",
        "Retorno:\n",
        "O item foi removido.\n",
        "\"\"\"\n",
        "item, modifiers = order.pop(int(n) - 1)\n",
        "return item\n",
        "def clear_order() -> None:\n",
        "\"\"\"Remove todos os itens do pedido do cliente.\"\"\"\n",
        "order.clear()\n",
        "def confirm_order() -> str:\n",
        "\"\"\"Pergunta ao cliente se o pedido está correto.\n",
        "Retorna:\n",
        "A resposta de texto livre do usuário.\n",
        "\"\"\"\n",
        "print('Seu pedido:')\n",
        "if not order:\n",
        "print(' (nenhum item)')\n",
        "for drink, modifiers in order:\n",
        "print(f' {drink}')\n",
        "if modifiers:\n",
        "print(f' - {\", \".join(modifiers)}')\n",
        "return input('Está correto? ')\n",
        "def place_order() -> int:\n",
        "\"\"\"Envie o pedido para a cozinha.\n",
        "Retorna:\n",
        "O número estimado de minutos até que o pedido esteja pronto.\n",
        "\"\"\"\n",
        "placed_order[:] = order.copy()\n",
        "clear_order()\n",
        "return randint(1, 10)"
      ],
      "metadata": {
        "id": "3hXLlXFrplI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "COFFEE_BOT_PROMPT = \"\"\"\\Você é um sistema de recebimento de pedidos de café\n",
        "e está restrito a falar apenas sobre bebidas do MENU. Nunca fale sobre nada\n",
        "além de pedir bebidas do MENU para o cliente.\n",
        "Seu objetivo é fazer place_order depois de compreender os itens do menu e\n",
        "quaisquer modificadores que o cliente queira.\n",
        "Adicione itens ao pedido do cliente com add_to_order, remova itens\n",
        "específicos com remove_item e redefina o pedido com clear_order.\n",
        "Para ver o conteúdo do pedido até agora, chame get_order (por padrão, isso é\n",
        "mostrado para você, não para o usuário)\n",
        "Sempre confirm_order com o usuário (verifique novamente) antes de chamar\n",
        "place_order. Chamar confirm_order exibirá os itens do pedido para o usuário\n",
        "e retornará sua resposta ao ver a lista. A sua resposta pode conter\n",
        "modificações.\n",
        "Sempre verifique e responda os nomes das bebidas e modificadores do MENU\n",
        "antes de adicioná-los ao pedido.\n",
        "Se você não tiver certeza de que uma bebida ou modificador corresponde aos\n",
        "do MENU, faça uma pergunta para esclarecer ou redirecionar.\n",
        "Você só tem os modificadores listados no cardápio abaixo: opções de leite,\n",
        "shots de café expresso, cafeína, adoçantes, pedidos especiais.\n",
        "Assim que o cliente terminar de fazer o pedido dos itens, confirm_order e\n",
        "depois place_order.\n",
        "Horário: terça, quarta, quinta, das 10h às 14h\n",
        "Preços: Todas as bebidas são gratuitas.\n",
        "CARDÁPIO:\n",
        "Bebidas de café:\n",
        "Espresso\n",
        "Americano\n",
        "Cold Brew\n",
        "Bebidas de Café com Leite:\n",
        "Latte\n",
        "Cappuccino\n",
        "Cortado\n",
        "Macchiato\n",
        "Mocha\n",
        "Flat White\n",
        "Bebidas de chá:\n",
        "English Breakfast Tea\n",
        "Green Tea\n",
        "Earl Grey\n",
        "Bebidas de chá com leite:\n",
        "Chai Latte\n",
        "Matcha Latte\n",
        "London Fog\n",
        "Outras bebidas:\n",
        "Vaporizador\n",
        "Chocolate quente\n",
        "Modificadores:\n",
        "Opções de leite: Integral, 2%, Aveia, Amêndoa, 2% Sem Lactose; Opção padrão:\n",
        "inteiro\n",
        "Shots de café expresso: Simples, Duplo, Triplo, Quádruplo; padrão: Duplo\n",
        "Cafeína: Descafeinado, Regular; padrão: Regular\n",
        "Quente-Gelado: Quente, Gelado; Padrão: Quente\n",
        "Adoçantes (opção de adicionar um ou mais): adoçante de baunilha, adoçante de\n",
        "avelã, calda de caramelo, calda de chocolate, adoçante de baunilha sem\n",
        "açúcar\n",
        "Pedidos especiais: qualquer modificação razoável que não envolva itens que\n",
        "não estejam no cardápio, por exemplo: ‘extra quente’, ‘one pump’, ‘half\n",
        "caff’, ‘extra foam’, etc.\n",
        "\"sujo\" significa adicionar uma dose de café expresso a uma bebida que\n",
        "normalmente não o contém, como \"Dirty Chai Latte\".\n",
        "“Leite normal” é o mesmo que “leite integral”.\n",
        "“Adoçado” significa adicionar um pouco de açúcar normal, não um adoçante.\n",
        "Hoje ficamos sem leite de soja, então a soja não está disponível.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "wfzTdm4Npqqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ordering_system = [add_to_order, get_order, remove_item, clear_order,\n",
        "confirm_order, place_order]\n",
        "\n",
        "1.0 Pro.\n",
        "use_sys_inst = False\n",
        "model_name = 'gemini-1.5-pro-latest' if use_sys_inst else 'gemini-1.0-pro\u0002latest'\n",
        "if use_sys_inst:\n",
        "model = genai.GenerativeModel(\n",
        "model_name, tools=ordering_system,\n",
        "system_instruction=COFFEE_BOT_PROMPT)\n",
        "convo = model.start_chat(enable_automatic_function_calling=True)\n",
        "else:\n",
        "model = genai.GenerativeModel(model_name, tools=ordering_system)\n",
        "convo = model.start_chat(\n",
        "history=[\n",
        "{'role': 'user', 'parts': [COFFEE_BOT_PROMPT]},\n",
        "{'role': 'model', 'parts': ['Ok, eu entendo. Eu farei o meu\n",
        "melhor!']}\n",
        "],\n",
        "enable_automatic_function_calling=True)\n",
        "@retry.Retry(initial=30)\n",
        "def send_message(message):\n",
        "return convo.send_message(message)\n",
        "placed_order = []\n",
        "order = []\n"
      ],
      "metadata": {
        "id": "qTV5Fp1opt0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown\n",
        "print('Bem vindo ao café Unifatec-PR!\\n\\n')\n",
        "while not placed_order:\n",
        "response = send_message(input('> '))\n",
        "display(Markdown(response.text))\n",
        "print('\\n\\n')\n",
        "print('[sessão do bot barista is dead]')\n",
        "print()\n",
        "print('Seu pedido:')\n",
        "print(f' {placed_order}\\n')\n",
        "print('- Obrigado por usar o Barista Bot!')\n"
      ],
      "metadata": {
        "id": "XFF7FsFspwz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.chat.util import Chat, reflections\n",
        "\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "\n",
        "conversa = [\n",
        "    [\"Oi\", [\"Olá! Bem-vindo ao Chatbot do Beto Carrero World. Como posso ajudar?\"]],\n",
        "    [\"Quais são os horários de funcionamento?\", [\"O parque funciona de terça-feira a domingo, das 9h30 às 18h30.\"]],\n",
        "    [\"Qual é o preço do ingresso?\", [\"Os preços dos ingressos variam de acordo com a idade e o tipo de ingresso. Você pode verificar os preços atualizados no nosso site.\"]],\n",
        "    [\"Quais atrações estão disponíveis?\", [\"Oferecemos uma variedade de atrações emocionantes, como montanhas-russas, shows ao vivo, zoológico, e muito mais. Você pode encontrar mais informações sobre nossas atrações no nosso site.\"]],\n",
        "    [\"Como chegar ao parque?\", [\"O Beto Carrero World está localizado em Penha, Santa Catarina, Brasil. Você pode chegar de carro ou ônibus. Também oferecemos pacotes com transporte incluso.\"]],\n",
        "    [\"Obrigado\", [\"Por nada! Se tiver mais alguma dúvida, estou aqui para ajudar.\"]],\n",
        "    [\"\", [\"Desculpe, não entendi. Você poderia repetir, por favor?\"]]\n",
        "]\n",
        "\n",
        "chatbot = Chat(conversa, reflections)\n",
        "\n",
        "\n",
        "def main():\n",
        "    print(\"Bem-vindo ao Chatbot do Beto Carrero World! Como posso ajudar?\")\n",
        "\n",
        "    while True:\n",
        "        mensagem = input(\"Você: \")\n",
        "        resposta = chatbot.respond(mensagem)\n",
        "        print(\"Chatbot: \" + resposta)\n",
        "\n",
        "        if mensagem.lower() == 'sair':\n",
        "            print(\"Obrigado por usar o Chatbot do Beto Carrero World. Até mais!\")\n",
        "            break\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "yJE6tyQGqM4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "from PyPDF2 import PdfReader\n",
        "import spacy\n",
        "\n",
        "\n",
        "def baixar_curriculo(url, nome_arquivo):\n",
        "    response = requests.get(url)\n",
        "    with open(nome_arquivo, 'wb') as f:\n",
        "        f.write(response.content)\n",
        "\n",
        "\n",
        "def extrair_texto_pdf(nome_arquivo):\n",
        "    with open(nome_arquivo, '/content/Profile.pdf') as f:\n",
        "        reader = PdfReader(f)\n",
        "        texto = ''\n",
        "        for page in reader.pages:\n",
        "            texto += page.extract_text()\n",
        "        return texto\n",
        "\n",
        "\n",
        "def avaliar_curriculo(texto_curriculo):\n",
        "\n",
        "\n",
        "    return \"Avaliação do currículo: Placeholder\"\n",
        "\n",
        "\n",
        "url_curriculo = \"URL_PARA_O_SEU_CURRICULO_EM_PDF\"\n",
        "nome_arquivo_curriculo = \"meu_curriculo.pdf\"\n",
        "\n",
        "baixar_curriculo(url_curriculo, nome_arquivo_curriculo)\n",
        "\n",
        "\n",
        "texto_curriculo = extrair_texto_pdf(nome_arquivo_curriculo)\n",
        "\n",
        "\n",
        "resultado_avaliacao = avaliar_curriculo(texto_curriculo)\n",
        "\n",
        "print(resultado_avaliacao)"
      ],
      "metadata": {
        "id": "GwS1tu87rgf8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}